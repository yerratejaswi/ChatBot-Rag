# ChatBot-Rag
Perfect Teja ğŸ˜
Hereâ€™s a **clean, professional, resume-grade README.md** for your RAG project.

You can copy-paste this directly into a file named:

```bash
README.md
```

---

# ğŸ“„ `README.md`

```markdown
# ChatBot-RAG ğŸš€

A modular Retrieval-Augmented Generation (RAG) chatbot built using:

- FastAPI
- FAISS (vector search)
- SentenceTransformers (MiniLM embeddings)
- OpenAI (LLM generation)
- Modular pipeline architecture

This project demonstrates a production-style RAG system with clean separation of responsibilities across ingestion, retrieval, validation, summarization, and generation stages.

---

## ğŸ§  Architecture Overview

The pipeline follows this flow:

Planner  
â†’ Retriever (FAISS cosine similarity search)  
â†’ Summarizer (context compression)  
â†’ Validator (confidence filtering)  
â†’ Generator (LLM answer synthesis)

```

User Query
â†“
Planner (detect type + top_k)
â†“
Retriever (vector search)
â†“
Summarizer (build context)
â†“
Validator (confidence + threshold check)
â†“
OpenAI Generator
â†“
Final Answer

```

---

## ğŸ“‚ Project Structure

```

app/
â”‚
â”œâ”€â”€ ingest/
â”‚   â”œâ”€â”€ chunker.py
â”‚   â”œâ”€â”€ embedder.py
â”‚   â””â”€â”€ loader.py
â”‚
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ planner.py
â”‚   â”œâ”€â”€ retriever.py
â”‚   â”œâ”€â”€ summarizer.py
â”‚   â”œâ”€â”€ validator.py
â”‚   â”œâ”€â”€ generator.py
â”‚   â””â”€â”€ pipeline.py
â”‚
â””â”€â”€ web/
â””â”€â”€ main.py

````

---

## ğŸ”¥ Features

- Sentence-based chunking
- MiniLM embeddings
- FAISS cosine similarity vector search
- Confidence-based validation layer
- Context size control
- Modular RAG pipeline
- PDF + TXT ingestion
- Session-scoped in-memory indexing

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/yerratejaswi/ChatBot-Rag.git
cd ChatBot-Rag
````

### 2ï¸âƒ£ Create Virtual Environment

```bash
python -m venv venv
venv\Scripts\activate  # Windows
# OR
source venv/bin/activate  # Mac/Linux
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

If no requirements file exists yet:

```bash
pip install fastapi uvicorn sentence-transformers faiss-cpu openai pymupdf numpy
```

---

## ğŸ”‘ Set OpenAI API Key

Windows (PowerShell):

```powershell
setx OPENAI_API_KEY "your_api_key_here"
```

Mac/Linux:

```bash
export OPENAI_API_KEY="your_api_key_here"
```

Restart terminal after setting.

---

## ğŸš€ Run Application

```bash
uvicorn app.web.main:app --reload
```

Open browser:

```
http://127.0.0.1:8000
```

---

## ğŸ“„ Upload Documents

Supported formats:

* `.txt`
* `.pdf`

Documents are indexed in-memory for the current session.

---

## ğŸ§ª Example Query

```
Explain the main idea discussed in the document.
```

---

## ğŸ— Technical Design Decisions

### Why Cosine Similarity?

MiniLM embeddings perform best using normalized vectors and cosine similarity.
FAISS `IndexFlatIP` with L2 normalization is used for optimal semantic retrieval.

### Why Validator Layer?

Prevents hallucinations by:

* Enforcing minimum similarity threshold
* Requiring sufficient context length

### Why Modular Architecture?

Improves:

* Testability
* Maintainability
* Extensibility (e.g., adding rerankers or hybrid search)

---

## ğŸ“ˆ Future Improvements

* Persistent FAISS index
* Hybrid BM25 + vector search
* Streaming LLM responses
* Multi-user session isolation
* Docker containerization
* Deployment to AWS / Azure

---

## ğŸ‘¨â€ğŸ’» Author

Tejaswi Yerra
Software Engineer | AI Systems | Cloud & Distributed Architectures

---

## â­ If You Like This Project

Give it a star and feel free to fork!



